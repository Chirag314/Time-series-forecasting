{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Copy of Untitled9.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOAhpaHGH3Lany733t5ftId",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Chirag314/Time-series-forecasting/blob/main/Copy_of_Untitled9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rNizq_QIGedf"
      },
      "outputs": [],
      "source": [
        "\n",
        "import urllib\n",
        "import zipfile\n",
        "\n",
        "import pandas as pd\n",
        "import tensorflow as tf\n",
        "import tensorflow as tf\n",
        "from tensorflow import keras\n",
        "import numpy as np\n",
        "\n",
        "# This function downloads and extracts the dataset to the directory that\n",
        "# contains this file.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "# (unless you need to change https to http)\n",
        "def download_and_extract_data():\n",
        "    url = 'https://storage.googleapis.com/download.tensorflow.org/data/certificate/household_power.zip'\n",
        "    urllib.request.urlretrieve(url, 'household_power.zip')\n",
        "    with zipfile.ZipFile('household_power.zip', 'r') as zip_ref:\n",
        "        zip_ref.extractall()\n",
        "\n",
        "\n",
        "# This function normalizes the dataset using min max scaling.\n",
        "# DO NOT CHANGE THIS CODE\n",
        "def normalize_series(data, min, max):\n",
        "    data = data - min\n",
        "    data = data / max\n",
        "    return data\n",
        "\n",
        "\n",
        "# This function is used to map the time series dataset into windows of\n",
        "# features and respective targets, to prepare it for training and\n",
        "# validation. First element of the first window will be the first element of\n",
        "# the dataset. Consecutive windows are constructed by shifting\n",
        "# the starting position of the first window forward, one at a time (indicated\n",
        "# by shift=1). For a window of n_past number of observations of all the time\n",
        "# indexed variables in the dataset, the target for the window\n",
        "# is the next n_future number of observations of these variables, after the\n",
        "# end of the window.\n",
        "\n",
        "# DO NOT CHANGE THIS CODE\n",
        "def windowed_dataset(series, batch_size, n_past=24, n_future=24, shift=1):\n",
        "    ds = tf.data.Dataset.from_tensor_slices(series)\n",
        "    ds = ds.window(size=n_past + n_future, shift=shift, drop_remainder=True)\n",
        "    ds = ds.flat_map(lambda w: w.batch(n_past + n_future))\n",
        "    ds = ds.map(lambda w: (w[:n_past], w[n_past:]))\n",
        "    return ds.batch(batch_size).prefetch(1)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "download_and_extract_data()\n",
        "    # Reads the dataset from the CSV.\n",
        "df = pd.read_csv('household_power_consumption.csv', sep=',',\n",
        "                     infer_datetime_format=True, index_col='datetime', header=0)"
      ],
      "metadata": {
        "id": "D6pIK-qUGiDy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2ghouUXoSk0",
        "outputId": "ded0cf4c-8038-42f8-b279-91ee5f0b9c74"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "86400"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "ZcNfmRhctken",
        "outputId": "9dc68f98-5eca-4615-be62-1f5546e9b8bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                     Global_active_power  Global_reactive_power  Voltage  \\\n",
              "datetime                                                                   \n",
              "2006-12-16 17:24:00                4.216                  0.418   234.84   \n",
              "2006-12-16 17:25:00                5.360                  0.436   233.63   \n",
              "2006-12-16 17:26:00                5.374                  0.498   233.29   \n",
              "2006-12-16 17:27:00                5.388                  0.502   233.74   \n",
              "2006-12-16 17:28:00                3.666                  0.528   235.68   \n",
              "\n",
              "                     Global_intensity  Sub_metering_1  Sub_metering_2  \\\n",
              "datetime                                                                \n",
              "2006-12-16 17:24:00              18.4             0.0             1.0   \n",
              "2006-12-16 17:25:00              23.0             0.0             1.0   \n",
              "2006-12-16 17:26:00              23.0             0.0             2.0   \n",
              "2006-12-16 17:27:00              23.0             0.0             1.0   \n",
              "2006-12-16 17:28:00              15.8             0.0             1.0   \n",
              "\n",
              "                     Sub_metering_3  \n",
              "datetime                             \n",
              "2006-12-16 17:24:00            17.0  \n",
              "2006-12-16 17:25:00            16.0  \n",
              "2006-12-16 17:26:00            17.0  \n",
              "2006-12-16 17:27:00            17.0  \n",
              "2006-12-16 17:28:00            17.0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-798ce76e-136a-4f42-a988-abbe9806ecbe\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Global_active_power</th>\n",
              "      <th>Global_reactive_power</th>\n",
              "      <th>Voltage</th>\n",
              "      <th>Global_intensity</th>\n",
              "      <th>Sub_metering_1</th>\n",
              "      <th>Sub_metering_2</th>\n",
              "      <th>Sub_metering_3</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>datetime</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:24:00</th>\n",
              "      <td>4.216</td>\n",
              "      <td>0.418</td>\n",
              "      <td>234.84</td>\n",
              "      <td>18.4</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:25:00</th>\n",
              "      <td>5.360</td>\n",
              "      <td>0.436</td>\n",
              "      <td>233.63</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>16.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:26:00</th>\n",
              "      <td>5.374</td>\n",
              "      <td>0.498</td>\n",
              "      <td>233.29</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:27:00</th>\n",
              "      <td>5.388</td>\n",
              "      <td>0.502</td>\n",
              "      <td>233.74</td>\n",
              "      <td>23.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2006-12-16 17:28:00</th>\n",
              "      <td>3.666</td>\n",
              "      <td>0.528</td>\n",
              "      <td>235.68</td>\n",
              "      <td>15.8</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>17.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-798ce76e-136a-4f42-a988-abbe9806ecbe')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-798ce76e-136a-4f42-a988-abbe9806ecbe button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-798ce76e-136a-4f42-a988-abbe9806ecbe');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "N_FEATURES = len(df.columns) # DO NOT CHANGE THIS\n",
        "\n",
        "    # Normalizes the data\n",
        "data = df.values\n",
        "data = normalize_series(data, data.min(axis=0), data.max(axis=0))\n",
        "\n",
        "    # Splits the data into training and validation sets.\n",
        "SPLIT_TIME = int(len(data) * 0.5) # DO NOT CHANGE THIS\n",
        "x_train = data[:SPLIT_TIME]\n",
        "x_valid = data[SPLIT_TIME:]\n",
        "\n",
        "    # DO NOT CHANGE THIS CODE\n",
        "tf.keras.backend.clear_session()\n",
        "tf.random.set_seed(42)\n",
        "\n",
        "    # DO NOT CHANGE BATCH_SIZE IF YOU ARE USING STATEFUL LSTM/RNN/GRU.\n",
        "    # THE TEST WILL FAIL TO GRADE YOUR SCORE IN SUCH CASES.\n",
        "    # In other cases, it is advised not to change the batch size since it\n",
        "    # might affect your final scores. While setting it to a lower size\n",
        "    # might not do any harm, higher sizes might affect your scores.\n",
        "BATCH_SIZE = 32  # ADVISED NOT TO CHANGE THIS\n",
        "\n",
        "    # DO NOT CHANGE N_PAST, N_FUTURE, SHIFT. The tests will fail to run\n",
        "    # on the server.\n",
        "    # Number of past time steps based on which future observations should be\n",
        "    # predicted\n",
        "N_PAST = 24  # DO NOT CHANGE THIS\n",
        "\n",
        "    # Number of future time steps which are to be predicted.\n",
        "N_FUTURE = 24  # DO NOT CHANGE THIS\n",
        "\n",
        "    # By how many positions the window slides to create a new window\n",
        "    # of observations.\n",
        "SHIFT = 1  # DO NOT CHANGE THIS\n",
        "\n",
        "    # Code to create windowed train and validation datasets.\n",
        "train_set = windowed_dataset(series=x_train, batch_size=BATCH_SIZE,\n",
        "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
        "                                 shift=SHIFT)\n",
        "valid_set = windowed_dataset(series=x_valid, batch_size=BATCH_SIZE,\n",
        "                                 n_past=N_PAST, n_future=N_FUTURE,\n",
        "                                 shift=SHIFT)\n"
      ],
      "metadata": {
        "id": "k1x3RJJtGq-J"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YW5vmyumu2ab",
        "outputId": "bb1acf3a-5ab8-46d4-9122-56c4d4a21e86"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(86400, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Shape of training data: {x_valid.shape}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uSli0ANHIsw",
        "outputId": "488c9817-c72a-4955-cac4-56e365a6ad99"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of training data: (43200, 7)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for element in train_set:\n",
        "  print(element)\n",
        "  import sys\n",
        "  sys.exit()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "YNcPSPuwVk0o",
        "outputId": "89b6f54f-61ff-4fe2-d4b6-17f8b9a6c6e0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(<tf.Tensor: shape=(32, 24, 7), dtype=float64, numpy=\n",
            "array([[[0.43377912, 0.47826087, 0.04036551, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.55716135, 0.49885584, 0.0355582 , ..., 0.        ,\n",
            "         0.01282051, 0.8       ],\n",
            "        [0.55867127, 0.56979405, 0.03420739, ..., 0.        ,\n",
            "         0.02564103, 0.85      ],\n",
            "        ...,\n",
            "        [0.81018119, 0.        , 0.0250298 , ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.73684211, 0.        , 0.02991657, ..., 0.        ,\n",
            "         0.        , 0.8       ],\n",
            "        [0.53710095, 0.        , 0.03778308, ..., 0.        ,\n",
            "         0.        , 0.85      ]],\n",
            "\n",
            "       [[0.55716135, 0.49885584, 0.0355582 , ..., 0.        ,\n",
            "         0.01282051, 0.8       ],\n",
            "        [0.55867127, 0.56979405, 0.03420739, ..., 0.        ,\n",
            "         0.02564103, 0.85      ],\n",
            "        [0.56018119, 0.57437071, 0.03599523, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        ...,\n",
            "        [0.73684211, 0.        , 0.02991657, ..., 0.        ,\n",
            "         0.        , 0.8       ],\n",
            "        [0.53710095, 0.        , 0.03778308, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.46160483, 0.        , 0.04084227, ..., 0.        ,\n",
            "         0.        , 0.85      ]],\n",
            "\n",
            "       [[0.55867127, 0.56979405, 0.03420739, ..., 0.        ,\n",
            "         0.02564103, 0.85      ],\n",
            "        [0.56018119, 0.57437071, 0.03599523, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.37446074, 0.60411899, 0.04370282, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        ...,\n",
            "        [0.53710095, 0.        , 0.03778308, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.46160483, 0.        , 0.04084227, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.32937877, 0.        , 0.04759634, ..., 0.        ,\n",
            "         0.        , 0.85      ]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0.32182916, 0.        , 0.04211363, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.27243313, 0.        , 0.04123957, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.38438309, 0.08695652, 0.03770362, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        ...,\n",
            "        [0.2366264 , 0.18077803, 0.04998014, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.47497843, 0.11441648, 0.03802145, ..., 0.        ,\n",
            "         0.25641026, 0.85      ],\n",
            "        [0.46699741, 0.08695652, 0.0378228 , ..., 0.        ,\n",
            "         0.11538462, 0.85      ]],\n",
            "\n",
            "       [[0.27243313, 0.        , 0.04123957, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.38438309, 0.08695652, 0.03770362, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.44736842, 0.10297483, 0.03611442, ..., 0.        ,\n",
            "         0.        , 0.8       ],\n",
            "        ...,\n",
            "        [0.47497843, 0.11441648, 0.03802145, ..., 0.        ,\n",
            "         0.25641026, 0.85      ],\n",
            "        [0.46699741, 0.08695652, 0.0378228 , ..., 0.        ,\n",
            "         0.11538462, 0.85      ],\n",
            "        [0.4322692 , 0.09382151, 0.03825983, ..., 0.        ,\n",
            "         0.01282051, 0.85      ]],\n",
            "\n",
            "       [[0.38438309, 0.08695652, 0.03770362, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.44736842, 0.10297483, 0.03611442, ..., 0.        ,\n",
            "         0.        , 0.8       ],\n",
            "        [0.46570319, 0.        , 0.03551847, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        ...,\n",
            "        [0.46699741, 0.08695652, 0.0378228 , ..., 0.        ,\n",
            "         0.11538462, 0.85      ],\n",
            "        [0.4322692 , 0.09382151, 0.03825983, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.46138913, 0.        , 0.03420739, ..., 0.        ,\n",
            "         0.01282051, 0.8       ]]])>, <tf.Tensor: shape=(32, 24, 7), dtype=float64, numpy=\n",
            "array([[[0.46160483, 0.        , 0.04084227, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.32937877, 0.        , 0.04759634, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.32808456, 0.        , 0.0443385 , ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        ...,\n",
            "        [0.46052632, 0.15560641, 0.03965038, ..., 0.        ,\n",
            "         0.47435897, 0.8       ],\n",
            "        [0.34534081, 0.16933638, 0.04576877, ..., 0.        ,\n",
            "         0.28205128, 0.9       ],\n",
            "        [0.31233822, 0.17391304, 0.04922527, ..., 0.        ,\n",
            "         0.15384615, 0.85      ]],\n",
            "\n",
            "       [[0.32937877, 0.        , 0.04759634, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.32808456, 0.        , 0.0443385 , ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.32722174, 0.        , 0.04338498, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        ...,\n",
            "        [0.34534081, 0.16933638, 0.04576877, ..., 0.        ,\n",
            "         0.28205128, 0.9       ],\n",
            "        [0.31233822, 0.17391304, 0.04922527, ..., 0.        ,\n",
            "         0.15384615, 0.85      ],\n",
            "        [0.38136324, 0.16475973, 0.04410012, ..., 0.        ,\n",
            "         0.34615385, 0.85      ]],\n",
            "\n",
            "       [[0.32808456, 0.        , 0.0443385 , ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.32722174, 0.        , 0.04338498, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        [0.33045729, 0.        , 0.04294795, ..., 0.        ,\n",
            "         0.        , 0.85      ],\n",
            "        ...,\n",
            "        [0.31233822, 0.17391304, 0.04922527, ..., 0.        ,\n",
            "         0.15384615, 0.85      ],\n",
            "        [0.38136324, 0.16475973, 0.04410012, ..., 0.        ,\n",
            "         0.34615385, 0.85      ],\n",
            "        [0.22799827, 0.18306636, 0.05065554, ..., 0.        ,\n",
            "         0.01282051, 0.85      ]],\n",
            "\n",
            "       ...,\n",
            "\n",
            "       [[0.4322692 , 0.09382151, 0.03825983, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.46138913, 0.        , 0.03420739, ..., 0.        ,\n",
            "         0.01282051, 0.8       ],\n",
            "        [0.28666954, 0.        , 0.04342471, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        ...,\n",
            "        [0.29314064, 0.05491991, 0.03710767, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.2299396 , 0.0617849 , 0.04004768, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.2232528 , 0.0617849 , 0.03969011, ..., 0.        ,\n",
            "         0.01282051, 0.85      ]],\n",
            "\n",
            "       [[0.46138913, 0.        , 0.03420739, ..., 0.        ,\n",
            "         0.01282051, 0.8       ],\n",
            "        [0.28666954, 0.        , 0.04342471, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.29486626, 0.        , 0.04199444, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        ...,\n",
            "        [0.2299396 , 0.0617849 , 0.04004768, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.2232528 , 0.0617849 , 0.03969011, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.22389991, 0.0617849 , 0.0420739 , ..., 0.        ,\n",
            "         0.01282051, 0.85      ]],\n",
            "\n",
            "       [[0.28666954, 0.        , 0.04342471, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.29486626, 0.        , 0.04199444, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.29616048, 0.        , 0.04513309, ..., 0.        ,\n",
            "         0.02564103, 0.85      ],\n",
            "        ...,\n",
            "        [0.2232528 , 0.0617849 , 0.03969011, ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.22389991, 0.0617849 , 0.0420739 , ..., 0.        ,\n",
            "         0.01282051, 0.85      ],\n",
            "        [0.22260569, 0.0617849 , 0.04147795, ..., 0.        ,\n",
            "         0.01282051, 0.85      ]]])>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "SystemExit",
          "evalue": "ignored",
          "traceback": [
            "An exception has occurred, use %tb to see the full traceback.\n",
            "\u001b[0;31mSystemExit\u001b[0m\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/IPython/core/interactiveshell.py:2890: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
            "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRsTLjowsycs",
        "outputId": "13725909-3747-4cec-8577-0a897f368dbf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(43200, 7)"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "\n",
        "        # ADD YOUR LAYERS HERE.\n",
        "\n",
        "        tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n",
        "                               strides=1, padding=\"causal\",\n",
        "                               activation=\"relu\",\n",
        "                               input_shape=[24, 7]),\n",
        "        tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "        tf.keras.layers.LSTM(64, return_sequences=True),\n",
        "        tf.keras.layers.Dense(30, activation=\"relu\"),\n",
        "        tf.keras.layers.Dense(10, activation=\"relu\"),\n",
        "\n",
        "        # If you don't follow the instructions in the following comments,\n",
        "        # tests will fail to grade your code:\n",
        "        # The input layer of your model must have an input shape of:\n",
        "        # (BATCH_SIZE, N_PAST = 24, N_FEATURES = 7)\n",
        "        # The model must have an output shape of:\n",
        "        # (BATCH_SIZE, N_FUTURE = 24, N_FEATURES = 7).\n",
        "        # Make sure that there are N_FEATURES = 7 neurons in the final dense\n",
        "        # layer since the model predicts 7 features.\n",
        "\n",
        "        # HINT: Bidirectional LSTMs may help boost your score. This is only a\n",
        "        # suggestion.\n",
        "\n",
        "        # WARNING: If you are using the GRU layer, it is advised not to use the\n",
        "        # recurrent_dropout argument (you can alternatively set it to 0),\n",
        "        # since it has not been implemented in the cuDNN kernel and may\n",
        "        # result in much longer training times.\n",
        "        tf.keras.layers.Dense(N_FEATURES)\n",
        "        \n",
        "    ])"
      ],
      "metadata": {
        "id": "YboKRVYMHmjc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NN7mdFpAJ34Y",
        "outputId": "8b60986f-03df-488b-ac27-9a082745eeba"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv1d (Conv1D)             (None, 24, 32)            1152      \n",
            "                                                                 \n",
            " lstm (LSTM)                 (None, 24, 64)            24832     \n",
            "                                                                 \n",
            " lstm_1 (LSTM)               (None, 24, 64)            33024     \n",
            "                                                                 \n",
            " dense (Dense)               (None, 24, 30)            1950      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 24, 10)            310       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 24, 7)             77        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 61,345\n",
            "Trainable params: 61,345\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "early_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
        "model.compile(\n",
        "        # YOUR CODE HERE\n",
        "         loss=\"mse\", optimizer = tf.keras.optimizers.SGD(learning_rate=1e-5),metrics=[tf.metrics.MeanAbsoluteError()]\n",
        "    )"
      ],
      "metadata": {
        "id": "WkT992usHoV6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(\n",
        "        # YOUR CODE HERE\n",
        "        train_set, epochs=5,validation_data=valid_set, callbacks=[ early_stopping], verbose=1\n",
        "    )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mcg7La_JHuJN",
        "outputId": "5233b424-5894-4d9a-d716-9e94246e8d85"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1349/1349 [==============================] - 58s 41ms/step - loss: 0.0644 - mean_absolute_error: 0.1367 - val_loss: 0.0647 - val_mean_absolute_error: 0.1335\n",
            "Epoch 2/5\n",
            "1349/1349 [==============================] - 46s 34ms/step - loss: 0.0639 - mean_absolute_error: 0.1366 - val_loss: 0.0642 - val_mean_absolute_error: 0.1334\n",
            "Epoch 3/5\n",
            "1349/1349 [==============================] - 46s 34ms/step - loss: 0.0634 - mean_absolute_error: 0.1366 - val_loss: 0.0637 - val_mean_absolute_error: 0.1333\n",
            "Epoch 4/5\n",
            "1349/1349 [==============================] - 46s 34ms/step - loss: 0.0629 - mean_absolute_error: 0.1365 - val_loss: 0.0633 - val_mean_absolute_error: 0.1332\n",
            "Epoch 5/5\n",
            "1349/1349 [==============================] - 46s 34ms/step - loss: 0.0625 - mean_absolute_error: 0.1364 - val_loss: 0.0628 - val_mean_absolute_error: 0.1331\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f72e4aa6790>"
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    }
  ]
}